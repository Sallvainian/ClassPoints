# System-Level Test Design

> **Generated by**: Test Architect (TEA) - System-Level Mode (Phase 3)
> **Date**: 2025-12-14
> **Project**: ClassPoints - Classroom Behavior Management App
> **Purpose**: Testability assessment for implementation readiness gate check

---

## Executive Summary

This document provides a **system-level testability assessment** of the ClassPoints architecture before proceeding to Sprint 0 implementation. The assessment evaluates architectural patterns against three testability criteria: Controllability, Observability, and Reliability.

**Overall Assessment**: **PASS WITH CONCERNS**

The architecture demonstrates strong testability foundations (context-based state management, isolated dependencies, proper cleanup patterns) but requires targeted improvements before comprehensive test implementation.

---

## Testability Assessment

### Controllability: CONCERNS

> Can tests set up precise preconditions and exercise specific behaviors?

| Aspect                    | Status     | Details                                                                                   |
| ------------------------- | ---------- | ----------------------------------------------------------------------------------------- |
| Mock Injection            | ✅ PASS    | Context-based architecture enables provider mocking (proven in `src/test/sounds.test.ts`) |
| Supabase Client Isolation | ✅ PASS    | Isolated in `src/lib/supabase.ts` - easily mockable at module level                       |
| Dependency Injection      | ✅ PASS    | Hooks receive dependencies via context, not hardcoded                                     |
| Test Data Factories       | ⚠️ CONCERN | No factory pattern for creating test fixtures                                             |
| E2E Selectors             | ⚠️ CONCERN | 0 `data-testid` attributes found - E2E tests will rely on fragile selectors               |
| Database Seeding          | ⚠️ CONCERN | No documented approach for test database setup/teardown                                   |

**Existing Mock Patterns** (from `src/test/sounds.test.ts:20-30`):

```typescript
vi.mock('../contexts/AuthContext', () => ({
  useAuth: vi.fn().mockReturnValue({
    user: { id: 'test-user-id' },
    session: { access_token: 'test-token' },
    loading: false,
    error: null,
  }),
  AuthProvider: ({ children }: { children: ReactNode }) => children,
}));
```

**Recommendation**: Create test utilities:

1. `src/test/factories/` - Test data factories (classrooms, students, behaviors)
2. `src/test/mocks/` - Reusable mock providers
3. Add `data-testid` attributes to interactive elements incrementally

### Observability: CONCERNS

> Can tests verify outcomes through explicit assertions?

| Aspect              | Status     | Details                                                                 |
| ------------------- | ---------- | ----------------------------------------------------------------------- |
| State Exposure      | ✅ PASS    | All state exposed via `useApp()` facade with clear loading/error states |
| Error Handling      | ✅ PASS    | Errors surfaced to UI through context error states                      |
| Sync Status         | ✅ PASS    | `syncStatus` in HybridAppContext exposes online/offline state           |
| Structured Logging  | ⚠️ CONCERN | Only `console.error` used - no structured logging for test assertions   |
| Metrics/Telemetry   | ⚠️ CONCERN | No performance metrics infrastructure                                   |
| Test-Specific Hooks | ⚠️ CONCERN | No test-specific data exposure (e.g., `data-testid`, ARIA labels)       |

**Recommendation**:

1. Add `data-testid` to key interactive elements (buttons, inputs, cards)
2. Consider ARIA labels for accessibility + testability dual benefit
3. Defer structured logging/metrics to post-MVP

### Reliability: PASS

> Do tests produce consistent, reproducible results?

| Aspect                     | Status  | Details                                                            |
| -------------------------- | ------- | ------------------------------------------------------------------ |
| Cleanup Patterns           | ✅ PASS | All `useEffect` hooks include proper cleanup (channel unsubscribe) |
| Stale Closure Prevention   | ✅ PASS | Refs pattern used for callbacks in realtime subscriptions          |
| Optimistic Update Rollback | ✅ PASS | Failed operations rollback optimistic state changes                |
| Test Isolation             | ✅ PASS | Context-based architecture allows isolated test renders            |
| Parallel Safety            | ✅ PASS | No global mutable state - tests can run in parallel                |

**Example of proper cleanup** (from `src/hooks/useRealtimeSubscription.ts:103-108`):

```typescript
return () => {
  if (channelRef.current) {
    supabase.removeChannel(channelRef.current);
    channelRef.current = null;
  }
};
```

---

## Architecturally Significant Requirements (ASRs)

Quality requirements from PRD NFRs that drive architectural decisions and require specific test strategies.

### DX Initiative NFRs (This Project)

| ASR      | Requirement                    | Probability | Impact | Score | Test Approach                                   |
| -------- | ------------------------------ | ----------- | ------ | ----- | ----------------------------------------------- |
| **NFR1** | Pre-commit hooks < 10 seconds  | 2           | 3      | **6** | CI benchmark tests with time assertions         |
| **NFR2** | Lint check < 30 seconds        | 2           | 2      | 4     | CI timing validation                            |
| **NFR3** | TypeScript check < 60 seconds  | 2           | 2      | 4     | CI timing validation                            |
| **NFR9** | CI/CD matches local validation | 3           | 3      | **9** | Parity tests: run same checks locally and in CI |

**Risk Scoring**: Score = Probability (1-3) × Impact (1-3)

- Score ≥6: Requires explicit test coverage
- Score = 9: Blocks release if untested

### Application Quality Requirements

| ASR                    | Requirement                          | Probability | Impact | Score | Test Approach                            |
| ---------------------- | ------------------------------------ | ----------- | ------ | ----- | ---------------------------------------- |
| **Auth Correctness**   | Users only see their own data        | 2           | 3      | **6** | Integration tests with RLS assertions    |
| **Realtime Sync**      | Point changes propagate immediately  | 2           | 2      | 4     | E2E tests with realtime assertions       |
| **Offline Resilience** | App works without Supabase           | 2           | 2      | 4     | Unit tests for localStorage fallback     |
| **Optimistic Updates** | UI responsive during network latency | 2           | 2      | 4     | Integration tests with delayed responses |

---

## Test Levels Strategy

Based on ClassPoints architecture (React + TypeScript + Supabase with realtime subscriptions):

### Recommended Split: 40 / 35 / 25

```
┌─────────────────────────────────────────────────────────────┐
│                       E2E Tests (25%)                       │
│         Critical user journeys, cross-system flows          │
├─────────────────────────────────────────────────────────────┤
│                  Integration Tests (35%)                    │
│      Context providers, hook interactions, API mocks        │
├─────────────────────────────────────────────────────────────┤
│                     Unit Tests (40%)                        │
│      Business logic, utilities, pure functions, hooks       │
└─────────────────────────────────────────────────────────────┘
```

### Rationale

| Level           | Percentage | Rationale                                                                                                          |
| --------------- | ---------- | ------------------------------------------------------------------------------------------------------------------ |
| **Unit**        | 40%        | Business logic, hooks, utilities, type transformations. Fastest feedback loop.                                     |
| **Integration** | 35%        | Context provider interactions are complex. Mock Supabase client, test state flows.                                 |
| **E2E**         | 25%        | Critical journeys only: login, award points, undo, classroom CRUD. Higher than typical due to realtime complexity. |

### Test Level Mapping

| Component Type                 | Test Level         | Examples                                          |
| ------------------------------ | ------------------ | ------------------------------------------------- |
| Utilities (`src/utils/`)       | Unit               | `formatDate`, `calculateTotal`, type guards       |
| Hooks (`src/hooks/`)           | Unit + Integration | Hook logic (unit), with context (integration)     |
| Contexts (`src/contexts/`)     | Integration        | Provider interactions, state management           |
| Components (`src/components/`) | Integration + E2E  | Rendered behavior (integration), user flows (E2E) |
| Database (RLS policies)        | Integration        | Supabase RLS policy assertions                    |
| Full Flows                     | E2E                | Login → Award Points → Undo → Logout              |

---

## NFR Testing Approach

### Performance (NFR1-NFR3)

| NFR                    | Test Type    | Tool                    | Implementation                      |
| ---------------------- | ------------ | ----------------------- | ----------------------------------- |
| NFR1: Pre-commit < 10s | CI Benchmark | GitHub Actions + timing | `time npm run pre-commit` assertion |
| NFR2: Lint < 30s       | CI Benchmark | GitHub Actions + timing | `time npm run lint` assertion       |
| NFR3: TypeScript < 60s | CI Benchmark | GitHub Actions + timing | `time npm run typecheck` assertion  |

**CI Implementation**:

```yaml
- name: Benchmark pre-commit
  run: |
    START=$(date +%s)
    npm run pre-commit
    END=$(date +%s)
    DURATION=$((END-START))
    if [ $DURATION -gt 10 ]; then
      echo "Pre-commit exceeded 10s ($DURATION s)"
      exit 1
    fi
```

### Security

| Concern             | Test Type   | Tool              | Implementation                          |
| ------------------- | ----------- | ----------------- | --------------------------------------- |
| Authentication      | E2E         | Playwright        | Login/logout flows, session persistence |
| Authorization (RLS) | Integration | Vitest + Supabase | Query with different user contexts      |
| Session Handling    | E2E         | Playwright        | Session timeout, refresh token          |

**RLS Test Pattern**:

```typescript
describe('RLS Policies', () => {
  it('should only return classrooms for authenticated user', async () => {
    // Create classroom as user A
    // Query as user B
    // Assert user B sees 0 classrooms
  });
});
```

### Reliability

| Concern        | Test Type   | Tool       | Implementation                                 |
| -------------- | ----------- | ---------- | ---------------------------------------------- |
| Offline Mode   | Unit        | Vitest     | Test localStorage fallback in HybridAppContext |
| Error Recovery | Integration | Vitest     | Simulate network failures, verify rollback     |
| Realtime Sync  | E2E         | Playwright | Multi-tab test with realtime assertions        |

### Maintainability

| Concern       | Test Type | Tool        | Target                           |
| ------------- | --------- | ----------- | -------------------------------- |
| Code Coverage | CI        | Vitest + c8 | 70% minimum (unit + integration) |
| Type Safety   | CI        | TypeScript  | Zero errors in strict mode       |
| Linting       | CI        | ESLint      | Zero warnings                    |

---

## Test Environment Requirements

### Local Development

| Requirement           | Implementation                                    |
| --------------------- | ------------------------------------------------- |
| Test Database         | Supabase local (`supabase start`) or test project |
| Environment Variables | `.env.test` with test-specific credentials        |
| Parallel Execution    | Vitest `--pool=threads` for unit/integration      |
| E2E Browser           | Playwright Chromium (minimal setup)               |

### CI Environment

| Requirement         | Implementation                                |
| ------------------- | --------------------------------------------- |
| Test Database       | Supabase test project or ephemeral local      |
| Secret Management   | GitHub Secrets for `DOTENV_PRIVATE_KEY_LOCAL` |
| Artifact Collection | Screenshot/video on E2E failure               |
| Parallel Jobs       | Separate jobs for unit, integration, E2E      |

### Test Data Strategy

| Approach         | Use Case                                             |
| ---------------- | ---------------------------------------------------- |
| Factories        | Unit/integration - in-memory test data               |
| Database Seeding | E2E - pre-populated test accounts                    |
| Cleanup          | `beforeEach`/`afterEach` reset, or per-test database |

---

## Testability Concerns

Issues requiring attention before or during Sprint 0:

### High Priority (Block Implementation)

| Concern                         | Impact                               | Mitigation                                  |
| ------------------------------- | ------------------------------------ | ------------------------------------------- |
| **No `data-testid` attributes** | E2E tests will use fragile selectors | Add incrementally as components are touched |
| **No test data factories**      | Duplicate test setup code            | Create `src/test/factories/` with builders  |

### Medium Priority (Address in Sprint 0)

| Concern                             | Impact                           | Mitigation                                  |
| ----------------------------------- | -------------------------------- | ------------------------------------------- |
| **Realtime subscription testing**   | Complex multi-client scenarios   | Use Playwright multi-page tests             |
| **Environment variable dependency** | Tests fail without `.env`        | Mock `import.meta.env` or use test env file |
| **RLS policy testing**              | Can't test without real Supabase | Use Supabase local or test project          |

### Low Priority (Post-MVP)

| Concern                    | Impact                          | Mitigation                                  |
| -------------------------- | ------------------------------- | ------------------------------------------- |
| **No structured logging**  | Can't assert log output         | Add logging layer if debugging becomes hard |
| **No performance metrics** | Can't track runtime performance | Add metrics if performance issues emerge    |

---

## Recommendations for Sprint 0

### Immediate Actions (Before Writing Tests)

1. **Create Test Infrastructure**

   ```
   src/test/
   ├── factories/
   │   ├── classroomFactory.ts
   │   ├── studentFactory.ts
   │   └── behaviorFactory.ts
   ├── mocks/
   │   ├── supabaseMock.ts
   │   └── authMock.ts
   └── utils/
       └── renderWithProviders.tsx
   ```

2. **Add `data-testid` Attributes**
   - Start with interactive elements (buttons, inputs)
   - Add to components as they're touched during development
   - Follow pattern: `data-testid="{component}-{element}"`

3. **Configure Test Environment**
   - Create `.env.test` with test Supabase credentials
   - Set up Supabase local or dedicated test project
   - Configure Vitest with proper module mocking

### CI Pipeline Setup

```yaml
# Recommended CI workflow structure
jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run lint
      - run: npm run typecheck

  test-unit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npm run test:unit -- --coverage

  test-e2e:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: npm ci
      - run: npx playwright install chromium
      - run: npm run test:e2e
```

### Test Coverage Targets

| Type        | Target                 | Rationale                           |
| ----------- | ---------------------- | ----------------------------------- |
| Unit        | 80%                    | Core logic should be well-tested    |
| Integration | 70%                    | Context interactions are critical   |
| E2E         | 100% of critical paths | Login, CRUD, point operations, undo |

---

## Appendix: Existing Test Analysis

### Current State

| Metric     | Value                                 |
| ---------- | ------------------------------------- |
| Test Files | 1 (`src/test/sounds.test.ts`)         |
| Test Lines | 347                                   |
| Framework  | Vitest + @testing-library/react       |
| E2E Tests  | 0 (framework configured but no tests) |

### Established Patterns (Reusable)

1. **Context Mocking**: `vi.mock()` for context providers
2. **Supabase Mocking**: Module-level mock with chainable methods
3. **AudioContext Mocking**: Web API mocking pattern
4. **Test Setup**: `@testing-library/jest-dom` imported in setup

### Gaps to Address

- No component rendering tests
- No hook testing with `renderHook`
- No integration tests for context interactions
- No E2E test implementation

---

## Validation Checklist

- [x] Testability assessment complete (3 criteria: Controllability, Observability, Reliability)
- [x] ASRs identified and risk-scored (4 DX NFRs + 4 application requirements)
- [x] Test levels strategy defined with rationale (40/35/25 split)
- [x] NFR testing approach per category (Performance, Security, Reliability, Maintainability)
- [x] Testability concerns documented (2 high, 3 medium, 2 low priority)
- [x] Sprint 0 recommendations provided (infrastructure, CI, coverage targets)
